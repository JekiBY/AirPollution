####################################################################################### Druid JSON READ
# number events to read:
 # 14400 per day as max, cause records made per 6 sec
#!!!!!!!!!!!!!##################### AUTOMATE 
source = "rno......_2"
tr = 28800
# ex: 1-3 selects  1st and 2nd day
#!!!!!!!!!!!!!##################### AUTOMATE
e_f = "22"
e_l = "24"
interval = "2017-06-"+e_f+"/2017-06-"+e_l

import json
url = 'http://broker.druid2.services.adx1.com/druid/v2/'
encoded_body = json.dumps({
   "queryType": "select",
   "dataSource": source,
   "descending": "false",
   "dimensions":[],
   "metrics":[],
   "granularity": "all",
   "intervals": [
     interval
   ],
   "pagingSpec":{"pagingIdentifiers": {}, "threshold":tr}
 })

http = urllib3.PoolManager()

r = http.request('POST', 'http://broker.druid2.services.adx1.com/druid/v2/',
                 headers={'Content-Type': 'application/json'},
                 body=encoded_body)

# Check selection from Druid , 200==works
status = r.status
# needed data!
response = r.data
#convert byte to string
response = str(response)
# delete b' at the begining and ' at the end

x = response[2:-1]


################################################################################# Druid JSON PARSE
import pandas as pd 
import numpy as np
from jsontraverse.parser import JsonTraverseParser
parser = JsonTraverseParser(x)
        
###################################################### 
#L1 - event index L2 - event attribute index  
#for each sensor read
from datetime import datetime

begin = datetime.now()
sec = range(20)
min = [19,39,59]
#df = pd.DataFrame(columns=("timestamp", "sensor_id", "device_id", "sensor_type", "temp", "ppb", "rh", "adccount", "count"))
df = pd.DataFrame(columns=("date", "month", "day", "hour", "minute", "sensor_id", "device_id", "sensor_type", "temp", "ppb", "rh"))

#read every event of threshold(=events from json read:
for L1 in range(tr):
    #check for empty vals(read all) and take data only for the 30nd minute and 29/30/31 sec in it => 1 val for each hour only
    if (parser.traverse("result.events."+str(L1)+".event.timestamp") is not None) & ( (pd.DatetimeIndex([parser.traverse("result.events."+str(L1)+".event.timestamp")]).minute in min) & (pd.DatetimeIndex([parser.traverse("result.events."+str(L1)+".event.timestamp")]).second in sec) ):
        L = list()
        a=[]
        for L2 in ["timestamp", "sensor_id", "device_id", "sensor_type", "temp", "ppb", "rh"]:
            XX2 =parser.traverse("result.events."+str(L1)+".event."+str(L2))
            L.append(XX2)
            
        a = np.array(L)
        a = a.reshape((1, 7))
        df2 = pd.DataFrame(data = a, columns=("timestamp", "sensor_id", "device_id", "sensor_type", "temp", "ppb", "rh"))
        
        #print (df2["timestamp"])
        # add new time features and remove timestamp
        df2= df2.assign(date = pd.DatetimeIndex(df2["timestamp"]).date)
        df2= df2.assign(month = pd.DatetimeIndex(df2["timestamp"]).month)
        df2= df2.assign(day = pd.DatetimeIndex(df2["timestamp"]).day)
        df2= df2.assign(hour = pd.DatetimeIndex(df2["timestamp"]).hour)
        df2= df2.assign(minute = pd.DatetimeIndex(df2["timestamp"]).minute)
        
        #rearrange column order
        df2 = df2[["date", "month", "day", "hour", "minute", "sensor_id", "device_id", "sensor_type", "temp", "ppb", "rh"]]
        """
        #check column names
        cols = list(df2.columns.values)
        """
              
        df = df.append(df2)
"""        print (df2["date"])
        print (df2["hour"])
        print(L1)
"""        
end = datetime.now() 
print( end - begin )   
print ( str(end)+'_'+str(begin) ) 
#!!!!!!!!!!!!!##################### AUTOMATE
# 1-3 06  7 minutes  wtf!?  but 22-24 06 1 minute
df.to_csv('C:/Contest/p_json_06_'+e_f+'-'+e_l+'_hrs.csv', sep = ';')

################################################################################################################


